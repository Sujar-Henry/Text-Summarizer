{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like humans, fish need oxygen to survive, so how do fish breathe underwater? \n",
      "\n",
      "Oxygen helps release the energy that powers our bodies from the sugary chemical glucose in a process called respiration. \n",
      "\n",
      "Respiration releases another gas, carbon dioxide, which gorillas, humans, and fish, breathe out. Humans inhale oxygen from the air, through their mouths, down into their lungs to breathe easily. \n",
      "\n",
      "However, fish have it much harder. \n",
      "\n",
      "To breathe, fish have to pull out molecules of oxygen dissolved in water using their gills, according to the Iowa Department of Natural Resources. \n",
      "\n",
      "The amount of oxygen in the air is a lot higher than the amount of oxygen in the water, though. \n",
      "\n",
      "That means that fish have a much more difficult time breathing than humans do. Fish take water into their mouths just like we take in air, opening and closing their lips. \n",
      "\n",
      "This water then filters through the gills, organs that have lots of feathery filaments made of protein molecules. \n",
      "\n",
      "The filaments look like tiny bristles on a brush. They have thousands of tiny blood vessels to help oxygen get into the bloodstream, even more blood vessels than in human lungs. \n",
      "\n",
      "The larger number of blood vessels in fish gives a much larger surface for oxygen to pass across. That helps them pull the dissolved oxygen from the water, and release carbon dioxide back into the water. \n"
     ]
    }
   ],
   "source": [
    "#Steps to create a summarizer:\n",
    "\"\"\"\n",
    "1. Read the text\n",
    "2. Tokenize the text\n",
    "3. Remove stop words\n",
    "4. Create a frequency table\n",
    "5. Tokenize the sentences\n",
    "6. Score the sentences\n",
    "7. Build the summary\n",
    "8. Output the summary\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "f = open(\"text.txt\",\"r\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Like', 1: 'humans', 2: ',', 3: 'fish', 4: 'need', 5: 'oxygen', 6: 'to', 7: 'survive', 8: ',', 9: 'so', 10: 'how', 11: 'do', 12: 'fish', 13: 'breathe', 14: 'underwater', 15: '?', 16: '\\n\\n', 17: 'Oxygen', 18: 'helps', 19: 'release', 20: 'the', 21: 'energy', 22: 'that', 23: 'powers', 24: 'our', 25: 'bodies', 26: 'from', 27: 'the', 28: 'sugary', 29: 'chemical', 30: 'glucose', 31: 'in', 32: 'a', 33: 'process', 34: 'called', 35: 'respiration', 36: '.', 37: '\\n\\n', 38: 'Respiration', 39: 'releases', 40: 'another', 41: 'gas', 42: ',', 43: 'carbon', 44: 'dioxide', 45: ',', 46: 'which', 47: 'gorillas', 48: ',', 49: 'humans', 50: ',', 51: 'and', 52: 'fish', 53: ',', 54: 'breathe', 55: 'out', 56: '.', 57: 'Humans', 58: 'inhale', 59: 'oxygen', 60: 'from', 61: 'the', 62: 'air', 63: ',', 64: 'through', 65: 'their', 66: 'mouths', 67: ',', 68: 'down', 69: 'into', 70: 'their', 71: 'lungs', 72: 'to', 73: 'breathe', 74: 'easily', 75: '.', 76: '\\n\\n', 77: 'However', 78: ',', 79: 'fish', 80: 'have', 81: 'it', 82: 'much', 83: 'harder', 84: '.', 85: '\\n\\n', 86: 'To', 87: 'breathe', 88: ',', 89: 'fish', 90: 'have', 91: 'to', 92: 'pull', 93: 'out', 94: 'molecules', 95: 'of', 96: 'oxygen', 97: 'dissolved', 98: 'in', 99: 'water', 100: 'using', 101: 'their', 102: 'gills', 103: ',', 104: 'according', 105: 'to', 106: 'the', 107: 'Iowa', 108: 'Department', 109: 'of', 110: 'Natural', 111: 'Resources', 112: '.', 113: '\\n\\n', 114: 'The', 115: 'amount', 116: 'of', 117: 'oxygen', 118: 'in', 119: 'the', 120: 'air', 121: 'is', 122: 'a', 123: 'lot', 124: 'higher', 125: 'than', 126: 'the', 127: 'amount', 128: 'of', 129: 'oxygen', 130: 'in', 131: 'the', 132: 'water', 133: ',', 134: 'though', 135: '.', 136: '\\n\\n', 137: 'That', 138: 'means', 139: 'that', 140: 'fish', 141: 'have', 142: 'a', 143: 'much', 144: 'more', 145: 'difficult', 146: 'time', 147: 'breathing', 148: 'than', 149: 'humans', 150: 'do', 151: '.', 152: 'Fish', 153: 'take', 154: 'water', 155: 'into', 156: 'their', 157: 'mouths', 158: 'just', 159: 'like', 160: 'we', 161: 'take', 162: 'in', 163: 'air', 164: ',', 165: 'opening', 166: 'and', 167: 'closing', 168: 'their', 169: 'lips', 170: '.', 171: '\\n\\n', 172: 'This', 173: 'water', 174: 'then', 175: 'filters', 176: 'through', 177: 'the', 178: 'gills', 179: ',', 180: 'organs', 181: 'that', 182: 'have', 183: 'lots', 184: 'of', 185: 'feathery', 186: 'filaments', 187: 'made', 188: 'of', 189: 'protein', 190: 'molecules', 191: '.', 192: '\\n\\n', 193: 'The', 194: 'filaments', 195: 'look', 196: 'like', 197: 'tiny', 198: 'bristles', 199: 'on', 200: 'a', 201: 'brush', 202: '.', 203: 'They', 204: 'have', 205: 'thousands', 206: 'of', 207: 'tiny', 208: 'blood', 209: 'vessels', 210: 'to', 211: 'help', 212: 'oxygen', 213: 'get', 214: 'into', 215: 'the', 216: 'bloodstream', 217: ',', 218: 'even', 219: 'more', 220: 'blood', 221: 'vessels', 222: 'than', 223: 'in', 224: 'human', 225: 'lungs', 226: '.', 227: '\\n\\n', 228: 'The', 229: 'larger', 230: 'number', 231: 'of', 232: 'blood', 233: 'vessels', 234: 'in', 235: 'fish', 236: 'gives', 237: 'a', 238: 'much', 239: 'larger', 240: 'surface', 241: 'for', 242: 'oxygen', 243: 'to', 244: 'pass', 245: 'across', 246: '.', 247: 'That', 248: 'helps', 249: 'them', 250: 'pull', 251: 'the', 252: 'dissolved', 253: 'oxygen', 254: 'from', 255: 'the', 256: 'water', 257: ',', 258: 'and', 259: 'release', 260: 'carbon', 261: 'dioxide', 262: 'back', 263: 'into', 264: 'the', 265: 'water', 266: '.'}\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the text\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Read the text from the file\n",
    "with open(\"text.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = {i: token.text for i, token in enumerate(doc)}\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
