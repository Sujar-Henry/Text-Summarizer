{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dog wants to breathe underwater so it will ask the fish how it can get gills.\n",
      "The fish tells the dog that it cannot grow gills but it can use a scuba mask, scuba masks are good.\n"
     ]
    }
   ],
   "source": [
    "#Steps to create a summarizer:\n",
    "\"\"\"\n",
    "1. Read the text\n",
    "2. Tokenize the text\n",
    "3. Remove stop words\n",
    "4. Create a frequency table\n",
    "5. Tokenize the sentences\n",
    "6. Score the sentences\n",
    "7. Build the summary\n",
    "8. Output the summary\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "f = open(\"text.txt\",\"r\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'The', 1: 'dog', 2: 'wants', 3: 'to', 4: 'breathe', 5: 'underwater', 6: 'so', 7: 'it', 8: 'will', 9: 'ask', 10: 'the', 11: 'fish', 12: 'how', 13: 'it', 14: 'can', 15: 'get', 16: 'gills', 17: '.', 18: '\\n', 19: 'The', 20: 'fish', 21: 'tells', 22: 'the', 23: 'dog', 24: 'that', 25: 'it', 26: 'can', 27: 'not', 28: 'grow', 29: 'gills', 30: 'but', 31: 'it', 32: 'can', 33: 'use', 34: 'a', 35: 'scuba', 36: 'mask', 37: ',', 38: 'scuba', 39: 'masks', 40: 'are', 41: 'good', 42: '.'}\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the text\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Read the text from the file\n",
    "with open(\"text.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = {}\n",
    "for i,token in enumerate(doc):\n",
    "        tokens[i] = token.text\n",
    "    \n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'to', 'so', 'it', 'will', 'the', 'how', 'it', 'can', 'get', 'The', 'the', 'that', 'it', 'can', 'not', 'but', 'it', 'can', 'a', 'are']\n",
      "['.', ',', '.']\n",
      "{1: 'dog', 2: 'wants', 4: 'breathe', 5: 'underwater', 9: 'ask', 11: 'fish', 16: 'gills', 18: '\\n', 20: 'fish', 21: 'tells', 23: 'dog', 28: 'grow', 29: 'gills', 33: 'use', 35: 'scuba', 36: 'mask', 38: 'scuba', 39: 'masks', 41: 'good'}\n"
     ]
    }
   ],
   "source": [
    "#Remove stop words and punctuation\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop_words = []\n",
    "punctuation = []\n",
    "\n",
    "for i,token in enumerate(doc):\n",
    "    if token.is_stop :\n",
    "        #show the stop words\n",
    "        stop_words.append(token.text)\n",
    "        del tokens[i]\n",
    "    elif token.is_punct:\n",
    "        punctuation.append(token.text)\n",
    "        del tokens[i]\n",
    "print(stop_words)\n",
    "print(punctuation)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 2, 'wants': 1, 'breathe': 1, 'underwater': 1, 'ask': 1, 'fish': 2, 'gills': 2, '\\n': 1, 'tells': 1, 'grow': 1, 'use': 1, 'scuba': 2, 'mask': 1, 'masks': 1, 'good': 1}\n",
      "{'dog': 1.0, 'wants': 0.5, 'breathe': 0.5, 'underwater': 0.5, 'ask': 0.5, 'fish': 1.0, 'gills': 1.0, '\\n': 0.5, 'tells': 0.5, 'grow': 0.5, 'use': 0.5, 'scuba': 1.0, 'mask': 0.5, 'masks': 0.5, 'good': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#Create a frequency table\n",
    "word_freq = {}\n",
    "\n",
    "for word in tokens.values():\n",
    "    if word not in word_freq:\n",
    "        word_freq[word] = 1\n",
    "    else:\n",
    "        word_freq[word] += 1\n",
    "print(word_freq)\n",
    "\n",
    "max_freq = max(word_freq.values())\n",
    "\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] = word_freq[word]/max_freq\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The dog wants to breathe underwater so it will ask the fish how it can get gills.\\n', 'The fish tells the dog that it cannot grow gills but it can use a scuba mask, scuba masks are good.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the sentences\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for i,token in enumerate(doc.sents):\n",
    "    sentences.append(token.text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The dog wants to breathe underwater so it will ask the fish how it can get gills.\\n': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#Score the sentences\n",
    "\n",
    "sentence_scores = {}\n",
    "for sent in sentences:\n",
    "    words = sent.split()\n",
    "    for word in sent:\n",
    "        if word.lower() in word_freq.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_freq[word.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_freq[word.lower()]\n",
    "print(sentence_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
